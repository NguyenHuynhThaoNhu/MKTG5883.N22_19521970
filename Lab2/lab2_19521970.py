# -*- coding: utf-8 -*-
"""Lab2_19521970.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uSZhZIBVBvvCEDdAqxrRVfIXzqUHdBXt
"""

from google.colab import files
 
 
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
#I.Pandas Introduction

# %matplotlib inline
import numpy as np
import pandas as pd
df = pd.read_csv("PastHires.csv")
df.head()

df.head(10)

df.tail(4)

df.shape

df.size

len(df)

df.columns

df['Hired']

df['Hired'][:5]

df['Hired'][5]

df[['Years Experience','Hired']]

df[['Years Experience','Hired']][:5]

df.sort_values(['Years Experience'])

degree_counts = df['Level of Education'].value_counts()
degree_counts

degree_counts.plot(kind='bar')

#II. Series
#1. Creating a Series

labels = ['a','b','c']
my_list = [10,20,30]
arr = np.array([10,20,30])
d = {'a':10,'b':20,'c':30}

pd.Series(data = my_list)

pd.Series(data = my_list, index = labels)

pd.Series(my_list, labels)

pd.Series(arr)

pd.Series(arr, labels)

#2. Data in Series

pd.Series(data = labels)

pd.Series([sum, print, len])

#3. Using an index

ser1 = pd.Series([1,2,3,4], index=['USA','Germany','USSR','Japan'])
ser1

ser2 = pd.Series([1,2,3,4], index=['USA','Germany','USSR','Japan'])
ser2

ser1['USA']

ser1+ser2

#III. DataFrames

from numpy.random import randn
np.random.seed(101)

df = pd.DataFrame(randn(5,4), index = 'A B C D E'.split(), columns = 'W X Y Z'.split())
df

#1. Selection and Indexing

df['W']

df[['W','Z']]

df.W

type(df['W'])

df['new'] = df['W'] + df['Y']
df

df.drop('new', axis = 1)

df

df.drop('new', axis = 1, inplace = True)
df

df.loc['A']

df.iloc[2]

df.loc['B','Y']

df.loc[['A','B'],['W','Y']]

#2. Conditional Selection

df

df > 0

df[df > 0]

df[df['W']>0]

df[df['W'] > 0][['Y','X']]

#3. More Index Details

df

df.reset_index()

newind = 'CA NY WY OR CO'.split()

df['States'] = newind

df

df.set_index('States')

df

df.set_index('States', inplace = True)

df

#4. Multi_Index and Index Hierarchy 

outside = ['G1','G1','G1','G2','G2','G2']
inside = [1,2,3,1,2,3]
hier_index = list (zip(outside,inside))
hier_index = pd.MultiIndex.from_tuples(hier_index)

hier_index

df = pd.DataFrame(np.random.randn(6,2), index = hier_index, columns=['A','B'])
df

df.loc['G1']

df.loc['G1'].loc[1]

df.index.names

df.index.names = ['Group','Num']

df

df.xs('G1')

df.xs(['G1',1])

df.xs(1,level='Num')

#IV. Missing Data

df = pd.DataFrame({'A':[1,2,np.nan],
                    'B':[5,np.nan,np.nan],
                   'C':[1,2,3]})
df

df.dropna(axis=1)

df.dropna(thresh=2)

df.fillna(value='FILL VALUE')

df['A'].fillna(value=df['A'].mean())

#1.GroupBy

import pandas as pd
data = {'Company' : ['GOOG','GOOG', 'MSFT', 'MSFT', 'FB','FB'],
      'Person':['Sam','Charlie','Amy','Vanessa','Carl','Sarah'],
      'Sales':[200,120,340,124,243,350]}

df = pd.DataFrame(data)

df

df.groupby('Company')

by_comp = df.groupby("Company")

by_comp.mean()

df.groupby('Company').mean()

by_comp.std()

by_comp.min()

by_comp.max()

by_comp.describe()

by_comp.describe().transpose()

by_comp.describe().transpose()['GOOG']

import pandas as pd

#V.Merging, Joining and Concatenating 
#1.Concatenation

df1 = pd.DataFrame({'A':['A0','A1','A2','A3'],
		                'B':['B0','B1','B2','B3'],
		                'C':['C0','C1','C2','C3'],
		                'D':['D0','D1','D2','D3']},
		                  index = [0,1,2,3])

df2 = pd.DataFrame({'A':['A4','A5','A6','A7'],
		    'B':['B4','B5','B6','B7'],
		    'C':['C4','C5','C6','C7'],
		    'D':['D4','D5','D6','D7']},
		    index = [4,5,6,7])

df3 = pd.DataFrame({'A':['A8','A9','A10','A11'],
		    'B':['B8','B9','B10','B11'],
		    'C':['C8','C9','C10','C11'],
		    'D':['D8','D9','D10','D11']},
		    index = [8,9,10,11])

df1

df2

df3

pd.concat([df1,df2,df3])

pd.concat([df1,df2,df3],axis=1)

#2. Merging
left = pd.DataFrame({'key':['K0','K1','K2','K3'],
		      'A':['A0','A1','A2','A3'],
		      'B':['B0','B1','B2','B3']})

right= pd.DataFrame({'key':['K0','K1','K2','K3'],
		      'A':['C0','C1','C2','C3'],
		      'B':['D0','D1','D2','D3']})

left

right

pd.merge(left,right,how='inner',on='key')

left = pd.DataFrame({'key1':['K0','K0','K1','K2'],
		     'key2':['K0','K1','K0','K1'],
		      'A':['A0','A1','A2','A3'],
		      'B':['B0','B1','B2','B3']})

right= pd.DataFrame({'key1':['K0','K1','K1','K2'],
		     'key2':['K0','K0','K0','K0'],
		      'A':['C0','C1','C2','C3'],
		      'B':['D0','D1','D2','D3']})

pd.merge(left,right,on=['key1','key2'])

pd.merge(left,right,how='outer',on=['key1','key2'])

pd.merge(left,right,how='right',on=['key1','key2'])

pd.merge(left,right,how='left',on=['key1','key2'])

#3.joining

left = pd.DataFrame({'A':['A0','A1','A2'],
		     'B':['B0','B1','B2']},
		   index=['K0','K1','K2'])

right= pd.DataFrame({'C':['C0','C1','C2'],
		     'D':['D0','D1','D2']},
		   index=['K0','K2','K3'])

left.join(right)

left.join(right,how='outer')

#V.Operations

df=pd.DataFrame({'col1':[1,2,3,4],
                 'col2':[444,555,666,444],
                 'col3':['abc','def','ghi','xyz']})

#1.Info on Unique Values

df['col2'].unique()

df['col2'].nunique()

df['col2'].value_counts()

#2. Selecting Data

newdf=df[(df['col1']>2) & (df['col2']==444)]

newdf

#3.Applying Functions

def times2(x):
	return x*2

df['col1'].apply(times2)

df['col3'].apply(len)

df['col1'].sum()

del df['col1']

df

df.columns

df.index

df

df.sort_values(by='col2')

df.isnull()

df.dropna()

import numpy as np

df = pd.DataFrame({'col1':[1,2,3,np.nan],
		   'col2':[np.nan,555,666,444],
		   'col3':['abc','def','ghi','xyz']})

df.head()

df.isnull()

df.dropna()

df.fillna('FILL')

data={'A':['foo','foo','foo','bar','bar','bar'],
      'B':['one','one','two','two','one','one'],
      'C':['x','y','x','y','x','y'],
      'D':[1,3,2,5,4,1]}

df=pd.DataFrame(data)
df

df.pivot_table(values='D',index=['A', 'B'],columns=['C'])

import numpy as np
import pandas as pd

from google.colab import files
 
uploaded = files.upload()

df = pd.read_csv('example.csv')
df

df.to_csv('example.csv', index = False)

pd.read_excel('example.xlsx',sheet_name='Sheet1')

df.to_excel('example.xlsx', sheet_name='Sheet1')

from sqlalchemy import create_engine

engine=create_engine('sqlite:///:memory:')

df.to_sql('data',engine)

sql_df = pd.read_sql('data',con=engine)

sql_df

